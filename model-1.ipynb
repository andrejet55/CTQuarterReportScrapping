{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction complete. The raw text has been saved for review.\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Step 1: Extract text from the PDF\n",
    "pdf_path = \"Q3-2024-Press-Release-English.pdf\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Extract text\n",
    "raw_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Save the raw text for review\n",
    "with open(\"extracted_text.txt\", \"w\") as f:\n",
    "    f.write(raw_text)\n",
    "\n",
    "print(\"Text extraction complete. The raw text has been saved for review.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'structured_text.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Load the raw text\n",
    "with open(\"extracted_text.txt\", \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# Step 1: Split the text into sections based on headings\n",
    "def split_into_sections(text):\n",
    "    # Match uppercase headings or headings followed by lines\n",
    "    headings = re.findall(r\"^[A-Z\\s\\-]+(?=\\n)\", text, re.MULTILINE)\n",
    "    sections = re.split(r\"^[A-Z\\s\\-]+(?=\\n)\", text, re.MULTILINE)\n",
    "    \n",
    "    # Combine headings and sections\n",
    "    structured_data = [{\"title\": title.strip(), \"content\": section.strip()} \n",
    "                       for title, section in zip(headings, sections[1:])]\n",
    "    return structured_data\n",
    "\n",
    "# Step 2: Clean and preprocess sections\n",
    "def clean_section(section):\n",
    "    # Remove table-like lines\n",
    "    section = re.sub(r\"\\s{2,}\", \" \", section)  # Replace extra spaces\n",
    "    section = re.sub(r\"[\\d]+\\s+[A-Za-z]+\\s+[A-Za-z]+\\s+\", \"\", section)  # Remove table rows\n",
    "    return section.strip()\n",
    "\n",
    "structured_sections = split_into_sections(raw_text)\n",
    "for section in structured_sections:\n",
    "    section[\"content\"] = clean_section(section[\"content\"])\n",
    "\n",
    "# Step 3: Save structured data for review\n",
    "output_path = \"structured_text.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(structured_sections, f, indent=4)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andressalguero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andressalguero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andressalguero/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cleaned_text.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Load the structured JSON file\n",
    "input_json_path = \"structured_text.json\"\n",
    "output_cleaned_path = \"cleaned_text.json\"\n",
    "\n",
    "with open(input_json_path, \"r\") as f:\n",
    "    structured_data = json.load(f)\n",
    "\n",
    "# Initialize preprocessing tools\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Clean all sections\n",
    "for section in structured_data:\n",
    "    section[\"cleaned_content\"] = clean_text(section[\"content\"])\n",
    "\n",
    "# Save the cleaned data\n",
    "with open(output_cleaned_path, \"w\") as f:\n",
    "    json.dump(structured_data, f, indent=4)\n",
    "\n",
    "output_cleaned_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA dataset saved to qa_dataset_advanced.json\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Load the cleaned text JSON file\n",
    "input_json_path = \"cleaned_text.json\"\n",
    "output_qa_path = \"qa_dataset_advanced.json\"\n",
    "\n",
    "with open(input_json_path, \"r\") as f:\n",
    "    cleaned_data = json.load(f)\n",
    "\n",
    "qa_dataset = []\n",
    "\n",
    "# Function to derive frequent words from the text\n",
    "def get_frequent_words(text, top_n=10):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())  # Extract words\n",
    "    stop_words = {\"the\", \"and\", \"of\", \"in\", \"to\", \"for\", \"a\", \"is\", \"on\", \"with\", \"by\", \"was\", \"at\", \"as\", \"it\"}\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return [word for word, count in word_counts.most_common(top_n)]\n",
    "\n",
    "# Function to derive questions based on patterns\n",
    "def derive_pattern_based_questions(context):\n",
    "    questions = []\n",
    "    if \"revenue\" in context.lower():\n",
    "        questions.append(\"What is the revenue?\")\n",
    "    if \"%\" in context:\n",
    "        questions.append(\"What percentage changes are mentioned?\")\n",
    "    if \"profit\" in context.lower():\n",
    "        questions.append(\"What is the profit mentioned in this section?\")\n",
    "    return questions\n",
    "\n",
    "# Function to derive questions and answers\n",
    "def derive_questions_and_answers(section):\n",
    "    questions_answers = []\n",
    "    context = section[\"cleaned_content\"]\n",
    "\n",
    "    # Generic Questions\n",
    "    generic_questions = [\n",
    "        \"What is this section about?\",\n",
    "        \"What is the main highlight?\",\n",
    "        \"What improvements are suggested?\",\n",
    "        \"What achievements are mentioned?\",\n",
    "    ]\n",
    "    for question in generic_questions:\n",
    "        questions_answers.append({\n",
    "            \"question\": question,\n",
    "            \"answers\": {\n",
    "                \"text\": [context[:100]],  # Use the first 100 characters as a brief summary\n",
    "                \"answer_start\": [0]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Specific Questions Based on Frequent Words\n",
    "    frequent_words = get_frequent_words(context)\n",
    "    for word in frequent_words:\n",
    "        if word in context:\n",
    "            questions_answers.append({\n",
    "                \"question\": f\"What is mentioned about '{word}'?\",\n",
    "                \"answers\": {\n",
    "                    \"text\": [context[context.find(word):context.find(word) + 50]],\n",
    "                    \"answer_start\": [context.find(word)]\n",
    "                }\n",
    "            })\n",
    "\n",
    "    # Questions Based on Patterns\n",
    "    pattern_questions = derive_pattern_based_questions(context)\n",
    "    for question in pattern_questions:\n",
    "        # Use the first 100 characters as a general answer for pattern-based questions\n",
    "        questions_answers.append({\n",
    "            \"question\": question,\n",
    "            \"answers\": {\n",
    "                \"text\": [context[:100]],\n",
    "                \"answer_start\": [0]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return context, questions_answers\n",
    "\n",
    "# Process each section to derive QA pairs\n",
    "for section in cleaned_data:\n",
    "    context, questions_answers = derive_questions_and_answers(section)\n",
    "    for qa in questions_answers:\n",
    "        qa_dataset.append({\n",
    "            \"context\": context,\n",
    "            \"question\": qa[\"question\"],\n",
    "            \"answers\": qa[\"answers\"]\n",
    "        })\n",
    "\n",
    "# Save the QA dataset to a JSON file\n",
    "with open(output_qa_path, \"w\") as f:\n",
    "    json.dump(qa_dataset, f, indent=4)\n",
    "\n",
    "print(f\"QA dataset saved to {output_qa_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined QA dataset saved to qa_dataset_refined.json\n"
     ]
    }
   ],
   "source": [
    "# Load the QA dataset\n",
    "input_json_path = \"qa_dataset_advanced.json\"\n",
    "output_json_path = \"qa_dataset_refined.json\"\n",
    "\n",
    "with open(input_json_path, \"r\") as f:\n",
    "    qa_dataset = json.load(f)\n",
    "\n",
    "refined_dataset = []\n",
    "\n",
    "# Function to derive question variations\n",
    "def generate_question_variations(base_question, keywords):\n",
    "    variations = []\n",
    "    for keyword in keywords:\n",
    "        variations.append(base_question.replace(\"this section\", f\"the {keyword}\"))\n",
    "    return variations\n",
    "\n",
    "# Function to refine answers\n",
    "def refine_answer(context, answer_text, start_pos):\n",
    "    # Ensure the answer is well-contained and concise\n",
    "    if start_pos < 0 or start_pos >= len(context):\n",
    "        return None, None  # Invalid position\n",
    "    answer_end = start_pos + len(answer_text)\n",
    "    if answer_end > len(context):\n",
    "        return None, None\n",
    "    return context[start_pos:answer_end], start_pos\n",
    "\n",
    "# Function to extract key entities or patterns\n",
    "def extract_entities(context):\n",
    "    entities = []\n",
    "    # Extract dates\n",
    "    entities += re.findall(r'\\b\\d{4}\\b', context)  # Years\n",
    "    # Extract percentages\n",
    "    entities += re.findall(r'\\b\\d+%|\\bpercent\\b', context.lower())\n",
    "    # Extract monetary values\n",
    "    entities += re.findall(r'\\$\\d+[,\\d]*', context)\n",
    "    return list(set(entities))  # Unique entities\n",
    "\n",
    "# Refine the dataset\n",
    "for qa_entry in qa_dataset:\n",
    "    context = qa_entry[\"context\"]\n",
    "    question = qa_entry[\"question\"]\n",
    "    answers = qa_entry[\"answers\"]\n",
    "\n",
    "    # Refine answers\n",
    "    refined_answer_text, refined_start_pos = refine_answer(\n",
    "        context, answers[\"text\"][0], answers[\"answer_start\"][0]\n",
    "    )\n",
    "    if refined_answer_text is None:\n",
    "        continue  # Skip invalid answers\n",
    "\n",
    "    # Generate additional questions based on entities\n",
    "    entities = extract_entities(context)\n",
    "    entity_questions = generate_question_variations(\n",
    "        \"What is mentioned about this section?\", entities\n",
    "    )\n",
    "\n",
    "    # Add original QA pair\n",
    "    refined_dataset.append({\n",
    "        \"context\": context,\n",
    "        \"question\": question,\n",
    "        \"answers\": {\n",
    "            \"text\": [refined_answer_text],\n",
    "            \"answer_start\": [refined_start_pos]\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Add entity-based QA pairs\n",
    "    for entity_question in entity_questions:\n",
    "        refined_dataset.append({\n",
    "            \"context\": context,\n",
    "            \"question\": entity_question,\n",
    "            \"answers\": {\n",
    "                \"text\": [refined_answer_text],\n",
    "                \"answer_start\": [refined_start_pos]\n",
    "            }\n",
    "        })\n",
    "\n",
    "# Save the refined dataset\n",
    "with open(output_json_path, \"w\") as f:\n",
    "    json.dump(refined_dataset, f, indent=4)\n",
    "\n",
    "print(f\"Refined QA dataset saved to {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the QA Dataset\n",
    "with open(\"qa_dataset_refined.json\", \"r\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# Convert the JSON dataset into a Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    \"context\": [entry[\"context\"] for entry in qa_data],\n",
    "    \"question\": [entry[\"question\"] for entry in qa_data],\n",
    "    \"answers\": [entry[\"answers\"] for entry in qa_data],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained BERT tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for tokenization\n",
    "def preprocess_data(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    start_char = example[\"answers\"][\"answer_start\"][0]\n",
    "    end_char = start_char + len(example[\"answers\"][\"text\"][0])\n",
    "    offsets = tokenized[\"offset_mapping\"]\n",
    "\n",
    "    # Find the start and end token indices\n",
    "    start_token_idx = end_token_idx = 0\n",
    "    for idx, (start, end) in enumerate(offsets):\n",
    "        if start <= start_char < end:\n",
    "            start_token_idx = idx\n",
    "        if start < end_char <= end:\n",
    "            end_token_idx = idx\n",
    "\n",
    "    tokenized[\"start_positions\"] = start_token_idx\n",
    "    tokenized[\"end_positions\"] = end_token_idx\n",
    "    tokenized.pop(\"offset_mapping\")  # Remove offset mapping as it's not needed for training\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60a6167cff14d2a8bf610024006f8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b275cc91b24b129018b4279a5f0f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the datasets\n",
    "train_dataset = train_dataset.map(preprocess_data, batched=False)\n",
    "eval_dataset = eval_dataset.map(preprocess_data, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-fine-tuned-qa\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8b/gvyhprgn3t764q19dkq1gt2c0000gp/T/ipykernel_92331/2976303973.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e238b0faeb87403590769b7bfdef7575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 8.6749, 'train_samples_per_second': 4.842, 'train_steps_per_second': 0.692, 'train_loss': 5.502456029256185, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=5.502456029256185, metrics={'train_runtime': 8.6749, 'train_samples_per_second': 4.842, 'train_steps_per_second': 0.692, 'total_flos': 10974463782912.0, 'train_loss': 5.502456029256185, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert-fine-tuned-qa/tokenizer_config.json',\n",
       " './bert-fine-tuned-qa/special_tokens_map.json',\n",
       " './bert-fine-tuned-qa/vocab.txt',\n",
       " './bert-fine-tuned-qa/added_tokens.json',\n",
       " './bert-fine-tuned-qa/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./bert-fine-tuned-qa\")\n",
    "tokenizer.save_pretrained(\"./bert-fine-tuned-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-import libraries to run a test only required if you are running the code in a different session\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"./bert-fine-tuned-qa\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(context, question):\n",
    "    # Tokenize input question and context\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        question, context, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Get logits\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    # Identify the most likely start and end tokens\n",
    "    start_idx = torch.argmax(start_scores).item()\n",
    "    end_idx = torch.argmax(end_scores).item()\n",
    "\n",
    "    # Validate start and end indices\n",
    "    if start_idx > end_idx:\n",
    "        print(\"Invalid span detected: Adjusting indices.\")\n",
    "        # Fallback: Choose tokens around the highest confidence start index\n",
    "        end_idx = min(start_idx + 5, len(input_ids) - 1)\n",
    "\n",
    "    # Decode tokens into the answer\n",
    "    answer_tokens = tokenizer.convert_ids_to_tokens(input_ids[start_idx:end_idx + 1])\n",
    "    answer = tokenizer.convert_tokens_to_string(answer_tokens).strip()\n",
    "\n",
    "    # Ensure answer is valid\n",
    "    if not answer or \"[CLS]\" in answer or \"[SEP]\" in answer:\n",
    "        answer = \"Unable to extract a confident answer.\"\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m Question\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat was the retail sales growth this quarter?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get the answer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m answer \u001b[38;5;241m=\u001b[39m answer_question(Context, Question)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQuestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36manswer_question\u001b[0;34m(context, question)\u001b[0m\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m      4\u001b[0m     question, context, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get logits\u001b[39;00m\n\u001b[1;32m     10\u001b[0m start_scores \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mstart_logits\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1950\u001b[0m, in \u001b[0;36mBertForQuestionAnswering.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;124;03mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;124;03m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;124;03m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1950\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[1;32m   1951\u001b[0m     input_ids,\n\u001b[1;32m   1952\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1953\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1954\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1955\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1956\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1957\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1958\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1959\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1960\u001b[0m )\n\u001b[1;32m   1962\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1964\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1079\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1080\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1081\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1082\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1083\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1084\u001b[0m )\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:211\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    208\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_ids)\n\u001b[1;32m    212\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# Example usage in a Jupyter cell\n",
    "Context= \"Retail sales increased by 15% this quarter. The company highlighted the success of its loyalty program.\"\n",
    "Question= \"What was the retail sales growth this quarter?\"\n",
    "\n",
    "\n",
    "# Get the answer\n",
    "answer = answer_question(Context, Question)\n",
    "print(f\"Question: {Question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Context= \"canadian tire corporation report third quarter result announces annual dividend increase th consecutive year share repurchase intention toronto november canadian tire corporation limited tsxctc tsx ctca ctc company today released third quarter result period ended september consolidated comparable salescompared q consolidated comparable sale compared q diluted normalized earnings per share eps compared q normalized basis annualized dividend increased per share alongside intention repurchase class non voting share delivered strong retail profitability third consecutive quarter sale trend improved said greg hick president ceo canadian tire corporation customer spending still constrained canadian seeking value finding triangle reward loyalty member earned redeemed u higher level quarter continue control cost manage margin carefully order balance lingering consumer economic headwind time investment made last two year position u well better omnichannel experience higher customer satisfaction score positive reaction new product hit shelf third quarter highlight consolidated comparable sale sportchek grew first quarter since q partially offset decline canadian tire retail ctr mark ctr comparable sale compared q customer continued prioritize essential category including automotive continued perform well strong quarter q led growth automotive service sportchek comparable sale marking two consecutive quarter sportchek outperformed industry trend targeted promotional event experience continued focus contributed growth athletic footwear hockey category mark comparable sale led industrial wear decline partially offset growth men short tshirts childrens wear top performer result ongoing strategic rollout category select mark store increased l oyalty engagement saw ctive registered loyalty member member took advantage offer engaged mass triangle promotion scanned loyalty card instore net promoter score np across company banner including ctr store investment focus strong stock availability key brand continued dr ive improvement positive customer sentiment improved retail profitability led higher consolidated income income tax ibt million increase normalized basisthe prior year retail ibt million normalized basis strong retail gross margin ratesolid cost control offset decline retail revenue ibt also benefited higher income equated around eps level result property sale gain insurance recovery financial service ibt quarter prior year higher net write offs operating expense partially offset higher revenue cardholder engagement remained strong gross average account receivable gaar mainly result higher average account balance ctc continues make solid progress key area within better connected strategy enhance customer experience drive efficiency almost capital invested since accomplishment third quarter included richer store digital customer experience store investment proceeding pace four new party city store added q refresh project expected completed end taking total since year end canadian tire expected deployed technology enhancement electronic shelf label locker ctc enhanced broadband capability supply chain productivity previously announced supply chain investment consolidation improving productivity saving including increased throughput result good toperson automation fully operational company calgary montreal distribution centre dc last stage planned supply chain investment include phased rollout ctc new transportation management system new vancouver dc set open continued margin accretion owned brand success continued strength category like automotive hockey contributing margin accretion owned brand penetrationdespite pressure discretionary category pipeline innovative quality owned brand product set roll consolidated overview revenue million compared period last year revenue excluding petroleum million decrease compared prior year consolidated income income tax million prior year normalized basis consolidated income income tax million diluted eps compared normalized basis prior year refer company q mda section normalizing item additional detail event impacted company quarter retail segment overview retail sale million compared third quarter retail sale excluding petroleumcomparable sale respectively ctr retail sale comparable sale period last year sportchek retail sale increased period last year comparable sale mark retail sale decreased period last year comparable sale helly hansen revenue compared period mainly due shift timing shipment wholesale customer retail revenue million decrease million compared prior year retail revenue excluding petroleum retail gross margin million compared third quarter prior year excluding petroleum retail gross margin rate excluding petroleum increased retail ibt q compared normalized basis prior year retail return invested capital roica trailing twelve month basis end third quarter compared end third quarter due decrease earnings prior period refer company q mda section normalizing item additional detail event impacted retail segment quarter financial service overview financial service segment income income tax quarter prior year higher net write offs operating expense partially offset higher revenue cardholder engag ement remained strong gaar relative prior year driven growth average account balance refer company q mda section detail event impacted financial service segment quarter ct reit overview diluted adjusted fund operation affo per unit compared q diluted net income per unit compared q announced three new investment totalling million expected add approximately incremental gross leasable area upon completion information refer q earnings release issued november capital expenditure total capital expenditure quarter compared q year todate basis operating capital expenditure quarter compared q full year expenditure expected company previously disclosed range million expenditure expected range million quarterly dividend company increased annual dividend th consecutive year voting class non voting share share increase approximately last year november company board director declared dividend payable march shareholder record january dividend considered eligible dividend tax purpose share repurchase november company announced intention repurchase class non voting share excess amount required anti dilutive purpose repurchase class non voting share made company existing normal course issuer bid ncib expires march thereafter renewed ncib subject regulatory approval non gaap financial measure ratio supplementary financial measure press release contains non gaap financial measure ratio supplementary financial measure reference q mda mean company management discussion analysis third quarter ended september available sedar httpwwwsedarplusca incorporated reference herein non gaap measure non gaap ratio standardized meaning gaap may comparable similar measure company nongaap financial measure ratio normalized diluted earnings per share normalized diluted eps non gaap ratio calculated dividing normalized net income attributable shareholder non gaap financial measure total diluted share company information measure see section company q mda following table reconciliation normalized net income attributable shareholder company respective gaap measure ytd ytd c million q q q q attributable shareholder item dc fire expense recovery gsthst related charge fair value redeemable financial instrument income income attributable shareholder eps non controlling interest included sum normalized net income attributable shareholder consolidated normalized income income tax retail normalized income income tax financial service normalized income income tax consolidated normalized income income tax retail normalized income income tax financial service normalized income income tax non gaap financial measure information measure see section com panys q mda table reconciles consolidated normalized income income tax income income tax ytd ytd c million q q q q income tax item dc fire expense recovery gsthst related charge fair value redeemable financial instrument income tax table reconciles retail normalized income income tax income income tax ytd ytd c million q q q q income tax le operating segment income tax item dc fire expense recovery income income tax table reconciles financial service normalized income income tax income income tax gaap measure reported consolidated financial statement ytd ytd c million q q q q income tax le operating segment income income tax item gsthst related charge normalized income income tax adjusted fund operation affo per unit affo per unit non gaap ratio calculated dividing affo weighted average number unit outstanding diluted basis affo non gaap financial measure following table reconciles gaap income income tax ffo reconciles ffo affo ytd ytd c million q q q q income tax le operating segment income income tax add ct reit fair value loss gain adjustment deferred tax lease principal payment right ofuse asset ct reit fair value equity award ct reit internal leasing expense fund operation le ct reit property straight line rent revenue ct reit direct leasing cost capital expenditure reserve adjusted fund operation invested capital roic roic calculated retail return divided retail invested capital retail return defined trailing annual retail tax earnings excluding interest expense lease related depreciation expense inter segment earnings normalizing em retail invested capital defined retail segment total asset le retail segment trade payable accrued liability inter segment balance based average trailing four quarter retail return retail invested capital non gaap financial measure information measure see section company q mda rolling c million q q income tax le operating segment income tax item operational efficiency program reduction related charge dc fire expense recovery income income tax le retail intercompany adjustment add retail interest expense right ofuse asset tax rate add retail tax retail return asset le average asset operating segment asset le average retail intercompany adjustment trade payable accrued liability trust asset invested capital include intercompany income received ct reit included retail segment inter company investment made retail segment ct reit ctfs trust accrued liability include trade payable short term derivative liability short term provision income tax payable expenditure operating capital expenditure non gaap financial measure information measure see section company q mda following table reconciles total addition investing activity reported consolidated statement cash flow operating capital expenditure ytd ytd c million q q q q total addition add accrued addition le ct reit acquisition development excluding vend in ctc expenditure appears consolidated statement cash flow investing activity b supplementary financial measure ratio measure supplementary financial measure see section supplementary financial measure company q mda information composition measure consolidated retail sale consolidated comparable sale revenue excluding petroleum retail revenue excluding petroleum retail sale retail sale excluding petroleum canadian tire retail comparable retail sale sportchek comparable retail sale mark comparable retail sale retail gross margin rate retail gross margin rate excluding petroleum gross average account receivables average account balance owned brand penetration forward looking statement press release contains information may constitute forward looking information within meaning applicable security law forward looking information provides insight regarding management current expectation plan allows investor others better understand company anticipated financial position result operation operating environment reader cautioned information may appropriate purpose although company belief forward looking information press release based information assumption belief current reasonable complete information necessarily subject number business economic competitive risk factor could cause actual result differ materially managem ents expectation plan set forth forward looking information company provide assurance financial operational performance plan aspiration forecast actually achieved achieved result increase company share price information material risk factor uncertainty material factor assumption applied preparing forward looking information could cause company actual result differ mater ially prediction forecast projection expectation conclusion refer section forward looking information investor communication company q mda well ctc public filing available httpswwwsedarplusca httpsinvestorscanadiantireca company undertake update forward looking information whether written oral may made time time behalf reflect new information future event otherwise except required applicable security law conference call canadian tire conduct conference call discus information included news release related matter et thursday november conference call available simultaneously entirety interested investor news medium webcast httpsinvestorscanadiantireca available replay website month canadian tire corporation canadian tire corporation limited tsx ctca tsx ctc ctc group company includes retail segment financial service division ct reit retail business led canadian tire founded c anadians product life canada across living playing fixing automotive seasonal gardening division party city partsource gas key part canadian tire network retail segment also includes mark leading sour ce casual industrial wear pro hockey life hockey specialty store catering elite player sportchek hockey expert sport expert atmosphere offer best active wear brand company close gasoline outlet supported strengthened ctc financial service division ten thousand people employed across canada around world ctc local dealer franchisees petroleum retailer addition ctc owns operates helly hansen leading technical outdoor brand based oslo norway information visit corpcanadiantireca information medium stephanie nadalin stephanienadalincantirecom investor karen keyes karenkeyescantirecom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid span detected: Adjusting indices.\n",
      "Question: How does Canadian Tire improve customer satisfaction?\n",
      "Answer: canadian tire corporation report third quarter\n"
     ]
    }
   ],
   "source": [
    "Question= \"How does Canadian Tire improve customer satisfaction?\"\n",
    "answer = answer_question(Context, Question)\n",
    "print(f\"Question: {Question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
