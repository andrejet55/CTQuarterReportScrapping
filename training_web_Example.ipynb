{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "based on: https://medium.com/geekculture/simple-chatbot-using-bert-and-pytorch-part-1-2735643e0baa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data preparation\n",
    "Put Q-A in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was Canadian Tire's diluted EPS in Q3 2024?</td>\n",
       "      <td>$3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was Canadian Tire's normalized EPS in Q3 ...</td>\n",
       "      <td>$2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the percentage decrease in consolidat...</td>\n",
       "      <td>1.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was Canadian Tire's annual dividend in 2024?</td>\n",
       "      <td>$7.10 per share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the increase in loyalty engagement in...</td>\n",
       "      <td>4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>What major investments were made to improve in...</td>\n",
       "      <td>Electronic shelf labels, lockers, and CTR stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Where is the conference call replay for Q3 202...</td>\n",
       "      <td>https://investors.canadiantire.ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>When was the press release issued regarding Q3...</td>\n",
       "      <td>November 7, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Who should media inquiries about Canadian Tire...</td>\n",
       "      <td>Stephanie Nadalin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Who should investor inquiries about Canadian T...</td>\n",
       "      <td>Karen Keyes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0    What was Canadian Tire's diluted EPS in Q3 2024?   \n",
       "1   What was Canadian Tire's normalized EPS in Q3 ...   \n",
       "2   What was the percentage decrease in consolidat...   \n",
       "3   What was Canadian Tire's annual dividend in 2024?   \n",
       "4   What was the increase in loyalty engagement in...   \n",
       "..                                                ...   \n",
       "56  What major investments were made to improve in...   \n",
       "57  Where is the conference call replay for Q3 202...   \n",
       "58  When was the press release issued regarding Q3...   \n",
       "59  Who should media inquiries about Canadian Tire...   \n",
       "60  Who should investor inquiries about Canadian T...   \n",
       "\n",
       "                                               Answer  \n",
       "0                                               $3.59  \n",
       "1                                               $2.96  \n",
       "2                                                1.5%  \n",
       "3                                     $7.10 per share  \n",
       "4                                                  4%  \n",
       "..                                                ...  \n",
       "56  Electronic shelf labels, lockers, and CTR stor...  \n",
       "57                  https://investors.canadiantire.ca  \n",
       "58                                   November 7, 2024  \n",
       "59                                  Stephanie Nadalin  \n",
       "60                                        Karen Keyes  \n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    (\"What was Canadian Tire's diluted EPS in Q3 2024?\", \"$3.59\"),\n",
    "    (\"What was Canadian Tire's normalized EPS in Q3 2024?\", \"$2.96\"),\n",
    "    (\"What was the percentage decrease in consolidated comparable sales in Q3 2024?\", \"1.5%\"),\n",
    "    (\"What was Canadian Tire's annual dividend in 2024?\", \"$7.10 per share\"),\n",
    "    (\"What was the increase in loyalty engagement in Q3 2024?\", \"4%\"),\n",
    "    (\"What was Canadian Tire's revenue in Q3 2024?\", \"$4,192.9 million\"),\n",
    "    (\"What was Canadian Tire's revenue excluding petroleum in Q3 2024?\", \"$3,639.8 million\"),\n",
    "    (\"What was the financial services segment IBT in Q3 2024?\", \"$110.3 million\"),\n",
    "    (\"What percentage increase was observed in GAAR in Q3 2024?\", \"3.0%\"),\n",
    "    (\"How many Party City stores were added in Q3 2024?\", \"Four\"),\n",
    "    (\"How many CTR store refresh projects are expected to be completed by the end of 2024?\", \"39\"),\n",
    "    (\"What is the expected range for 2025 operating capital expenditures?\", \"$525 million to $575 million\"),\n",
    "    (\"What was the retail segment IBT in Q3 2024?\", \"$164.8 million\"),\n",
    "    (\"What percentage decrease was observed in Mark’s retail sales in Q3 2024?\", \"2.0%\"),\n",
    "    (\"What was the consolidated income before taxes in Q3 2024?\", \"$299.3 million\"),\n",
    "    (\"What percentage of Canadian Tire stores are expected to have technology enhancements by year-end 2024?\", \"More than 90%\"),\n",
    "    (\"What technology enhancements are being deployed in Canadian Tire stores?\", \"Electronic shelf labels and lockers\"),\n",
    "    (\"What is the expected gross leasable area from CT REIT's new investments?\", \"Approximately 283,000 square feet\"),\n",
    "    (\"What was the retail gross margin rate excluding petroleum in Q3 2024?\", \"35.7%\"),\n",
    "    (\"What was Canadian Tire’s operating capital expenditures in Q3 2024?\", \"$127.1 million\"),\n",
    "    (\"How many retail locations will have enhanced broadband capabilities by the end of 2024?\", \"More than 60%\"),\n",
    "    (\"What was the diluted adjusted funds from operations per unit for CT REIT in Q3 2024?\", \"$0.339\"),\n",
    "    (\"What was the reported normalized net income attributable to shareholders in Q3 2024?\", \"$200.6 million\"),\n",
    "    (\"What caused a $0.41 EPS impact in Q3 2024?\", \"A property sale gain and insurance recoveries\"),\n",
    "    (\"What was the revenue decrease percentage for Helly Hansen in Q3 2024?\", \"6.0%\"),\n",
    "    (\"What is the dividend declared per share for March 2025?\", \"$1.775 per share\"),\n",
    "    (\"What was the key factor driving higher customer sentiment in Q3 2024?\", \"Improved in-store Net Promoter Score (NPS)\"),\n",
    "    (\"What strategic change improved supply chain productivity?\", \"Goods-to-person automation in Calgary and Montreal distribution centers\"),\n",
    "    (\"What is Canadian Tire's main operating capital expenditure priority for 2025?\", \"New Vancouver Distribution Center and transportation management system rollout\"),\n",
    "    (\"What non-GAAP measure reconciles normalized income before taxes?\", \"Normalized Income Before Income Taxes\"),\n",
    "    (\"Where is Canadian Tire Corporation headquartered?\", \"Toronto, Canada\"),\n",
    "    (\"When did Canadian Tire release its Q3 2024 results?\", \"November 7, 2024\"),\n",
    "    (\"What was the revenue excluding petroleum for Q3 2024?\", \"$3,639.8 million\"),\n",
    "    (\"Who is the President and CEO of Canadian Tire Corporation?\", \"Greg Hicks\"),\n",
    "    (\"When is the next dividend payable date for Canadian Tire shareholders?\", \"March 1, 2025\"),\n",
    "    (\"Was there an increase in consolidated income before income taxes compared to last year?\", \"Yes, it increased by $230.0 million.\"),\n",
    "    (\"What percentage of Canadian Tire retail locations will have enhanced broadband by 2024 year-end?\", \"More than 60%\"),\n",
    "    (\"Where were supply chain productivity improvements implemented?\", \"Calgary and Montreal Distribution Centres\"),\n",
    "    (\"What segment showed growth in comparable sales for two consecutive quarters?\", \"SportChek\"),\n",
    "    (\"Was there a decline in retail revenue in Q3 2024 compared to last year?\", \"Yes, it decreased by 1.8%\"),\n",
    "    (\"What category in Mark’s was a top performer in Q3 2024?\", \"Children’s wear\"),\n",
    "    (\"Who are the intended beneficiaries of the dividend increase?\", \"Shareholders of record as of January 31, 2025\"),\n",
    "    (\"When is the expiry date for Canadian Tire's current NCIB program?\", \"March 1, 2025\"),\n",
    "    (\"What event contributed to a $0.41 EPS impact in Q3 2024?\", \"A property sale gain and insurance recoveries\"),\n",
    "    (\"Were active registered loyalty members up in Q3 2024?\", \"Yes, by 4%\"),\n",
    "    (\"What was Canadian Tire's diluted adjusted funds from operations per unit in Q3 2024?\", \"$0.339\"),\n",
    "    (\"When did Canadian Tire's SportChek last show positive comparable sales before Q2 2024?\", \"Q2 2023\"),\n",
    "    (\"Where can the full Q3 2024 MD&A document be accessed?\", \"SEDAR+ at http://www.sedarplus.ca\"),\n",
    "    (\"What segment experienced a 6% decline in revenue in Q3 2024?\", \"Helly Hansen\"),\n",
    "    (\"When was Canadian Tire founded?\", \"1922\"),\n",
    "    (\"Where is Helly Hansen, one of Canadian Tire’s owned brands, based?\", \"Oslo, Norway\"),\n",
    "    (\"What financial measure includes gains from property sales and insurance recoveries?\", \"Consolidated Income Before Income Taxes\"),\n",
    "    (\"Were consolidated comparable sales up or down in Q3 2024?\", \"Down by 1.5%\"),\n",
    "    (\"Where are the new Party City stores located?\", \"Not specified in the document.\"),\n",
    "    (\"What contributed to increased customer satisfaction in Q3 2024?\", \"Better omnichannel experiences and strategic store investments\"),\n",
    "    (\"When will Canadian Tire’s new Vancouver Distribution Center open?\", \"2025\"),\n",
    "    (\"What major investments were made to improve in-store customer experience?\", \"Electronic shelf labels, lockers, and CTR store refresh projects\"),\n",
    "    (\"Where is the conference call replay for Q3 2024 available?\", \"https://investors.canadiantire.ca\"),\n",
    "    (\"When was the press release issued regarding Q3 2024 results?\", \"November 7, 2024\"),\n",
    "    (\"Who should media inquiries about Canadian Tire be directed to?\", \"Stephanie Nadalin\"),\n",
    "    (\"Who should investor inquiries about Canadian Tire be directed to?\", \"Karen Keyes\")\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Question\", \"Answer\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('QA_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was Canadian Tire's diluted EPS in Q3 2024?</td>\n",
       "      <td>$3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was Canadian Tire's normalized EPS in Q3 ...</td>\n",
       "      <td>$2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the percentage decrease in consolidat...</td>\n",
       "      <td>1.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was Canadian Tire's annual dividend in 2024?</td>\n",
       "      <td>$7.10 per share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the increase in loyalty engagement in...</td>\n",
       "      <td>4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question           Answer\n",
       "0   What was Canadian Tire's diluted EPS in Q3 2024?            $3.59\n",
       "1  What was Canadian Tire's normalized EPS in Q3 ...            $2.96\n",
       "2  What was the percentage decrease in consolidat...             1.5%\n",
       "3  What was Canadian Tire's annual dividend in 2024?  $7.10 per share\n",
       "4  What was the increase in loyalty engagement in...               4%"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('QA_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61 entries, 0 to 60\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  61 non-null     object\n",
      " 1   Answer    61 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer\n",
       "43    0.032787\n",
       "37    0.032787\n",
       "8     0.032787\n",
       "22    0.032787\n",
       "0     0.032787\n",
       "38    0.032787\n",
       "45    0.016393\n",
       "33    0.016393\n",
       "53    0.016393\n",
       "25    0.016393\n",
       "48    0.016393\n",
       "52    0.016393\n",
       "26    0.016393\n",
       "47    0.016393\n",
       "51    0.016393\n",
       "9     0.016393\n",
       "50    0.016393\n",
       "34    0.016393\n",
       "14    0.016393\n",
       "44    0.016393\n",
       "27    0.016393\n",
       "28    0.016393\n",
       "42    0.016393\n",
       "24    0.016393\n",
       "16    0.016393\n",
       "30    0.016393\n",
       "54    0.016393\n",
       "49    0.016393\n",
       "46    0.016393\n",
       "32    0.016393\n",
       "41    0.016393\n",
       "15    0.016393\n",
       "13    0.016393\n",
       "12    0.016393\n",
       "20    0.016393\n",
       "10    0.016393\n",
       "2     0.016393\n",
       "17    0.016393\n",
       "31    0.016393\n",
       "19    0.016393\n",
       "11    0.016393\n",
       "4     0.016393\n",
       "7     0.016393\n",
       "40    0.016393\n",
       "39    0.016393\n",
       "29    0.016393\n",
       "23    0.016393\n",
       "18    0.016393\n",
       "3     0.016393\n",
       "6     0.016393\n",
       "21    0.016393\n",
       "1     0.016393\n",
       "35    0.016393\n",
       "5     0.016393\n",
       "36    0.016393\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the answers into encodings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Answer'] = le.fit_transform(df['Answer'])\n",
    "# check class distribution\n",
    "df['Answer'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we have used all the utterances for training purpose\n",
    "train_text, train_labels = df[\"Question\"], df[\"Answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, BertTokenizerFast\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "# Import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "# Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Import Roberta pretrained model\n",
    "bert = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTILBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# Load the DistilBert tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# Import the DistilBert pretrained model\n",
    "bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2054,  2003,  3010, 12824,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  3010, 12824,  3840,  1010,  2003,  1037,  2177,  1997,  3316,\n",
      "          2008,  2950,  1037,  7027,  6903,  1010,  1037,  3361,  2578,  2407,\n",
      "          1998, 14931, 24964,  2102,  1012,  2256,  7027,  2449,  2003,  2419,\n",
      "          2011,  3010, 12824,  1010,  2029,  2001,  2631,  1999,  4798,  1998,\n",
      "          3640, 16485,  2007,  3688,  2005,  2166,  1999,  2710,  2408,  2049,\n",
      "          2542,  1010,  2652,  1010, 15887,  1010, 12945,  1998, 12348,  1004,\n",
      "         21529,  5908,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = [\"   What is Canadian Tire\",\"Canadian Tire Corporation, is a group of companies that includes a Retail segment, a Financial Services division and CT REIT. Our retail business is led by Canadian Tire, which was founded in 1922 and provides Canadians with products for life in Canada across its Living, Playing, Fixing, Automotive and Seasonal & Gardening divisions.\"]\n",
    "# Encode the text\n",
    "encoded_input = tokenizer(text, padding=True,truncation=True, return_tensors='pt')\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 10)\n",
    "# Based on the histogram we are selecting the max len as 8\n",
    "max_seq_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# DataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "   def __init__(self, bert):      \n",
    "       super(BERT_Arch, self).__init__()\n",
    "       self.bert = bert \n",
    "      \n",
    "       # dropout layer\n",
    "       self.dropout = nn.Dropout(0.2)\n",
    "      \n",
    "       # relu activation function\n",
    "       self.relu =  nn.ReLU()\n",
    "       # dense layer\n",
    "       self.fc1 = nn.Linear(768,512)\n",
    "       self.fc2 = nn.Linear(512,256)\n",
    "       self.fc3 = nn.Linear(256,5)\n",
    "       #softmax activation function\n",
    "       self.softmax = nn.LogSoftmax(dim=1)\n",
    "       #define the forward pass\n",
    "   def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      \n",
    "      x = self.fc2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      # output layer\n",
    "      x = self.fc3(x)\n",
    "   \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BERT_Arch                                               --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              (23,440,896)\n",
       "│    │    └─Embedding: 3-2                              (393,216)\n",
       "│    │    └─LayerNorm: 3-3                              (1,536)\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             (42,527,232)\n",
       "├─Dropout: 1-2                                          --\n",
       "├─ReLU: 1-3                                             --\n",
       "├─Linear: 1-4                                           393,728\n",
       "├─Linear: 1-5                                           131,328\n",
       "├─Linear: 1-6                                           1,285\n",
       "├─LogSoftmax: 1-7                                       --\n",
       "================================================================================\n",
       "Total params: 66,889,221\n",
       "Trainable params: 526,341\n",
       "Non-trainable params: 66,362,880\n",
       "================================================================================"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
    "for param in bert.parameters():\n",
    "      param.requires_grad = False\n",
    "model = BERT_Arch(bert)\n",
    "# push the model to GPU\n",
    "#model = model.to(device)\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Computed Weights: tensor([0.5545, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 0.5545,\n",
      "        1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091,\n",
      "        1.1091, 1.1091, 1.1091, 1.1091, 0.5545, 1.1091, 1.1091, 1.1091, 1.1091,\n",
      "        1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091,\n",
      "        1.1091, 0.5545, 0.5545, 1.1091, 1.1091, 1.1091, 1.1091, 0.5545, 1.1091,\n",
      "        1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091, 1.1091,\n",
      "        1.1091])\n"
     ]
    }
   ],
   "source": [
    "class_counts = np.bincount(train_labels)\n",
    "total_samples = len(train_labels)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "\n",
    "# Convert to tensor\n",
    "weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f\"Manually Computed Weights: {weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea FS\\AppData\\Local\\Temp\\ipykernel_2520\\4216351222.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights= torch.tensor(weights,dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(weights,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "# number of training epochs\n",
    "epochs = 200\n",
    "# We can also use learning rate scheduler to achieve better results\n",
    "lr_sch = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_preds = []  # List to save predictions\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and step != 0:\n",
    "            print(f'Batch {step} of {len(train_dataloader)}.')\n",
    "\n",
    "        # No need to push to GPU; ensure tensors are already on CPU\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Optimizer step and clear gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Detach predictions and append\n",
    "        preds = preds.detach().numpy()  # Since we're on CPU, no need for `.cpu()`\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 200\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 5 classes or no classes but got weight tensor of shape: [55]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Append training loss\u001b[39;00m\n\u001b[0;32m      8\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[74], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     14\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(sent_id, mask)\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:251\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrea FS\\OneDrive\\Lambton college\\second term\\new_nlp\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3148\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3147\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3149\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\n\u001b[0;32m   3150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: weight tensor should be defined either for all 5 classes or no classes but got weight tensor of shape: [55]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
    "\n",
    "    # Train the model\n",
    "    train_loss, _ = train()\n",
    "\n",
    "    # Append training loss\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Set deterministic behavior (optional for reproducibility)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f'\\nFinal Training Loss: {train_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
